{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index","text":""},{"location":"#kybershards","title":"KyberShards","text":"<p>A modular Python library providing implementations of machine learning components, data structures, and analysis tools for data science</p>"},{"location":"#introduction","title":"Introduction","text":"<p>KyberShards is a Python library designed to provide modular, efficient implementations of essential tools for data science and machine learning workflows. Whether you're exploring data, building models, or analyzing results, KyberShards aims to provide robust components that work seamlessly together while maintaining flexibility for customization.</p> <p>The library is designed with both clarity and performance in mind, making it suitable for educational settings as well as production environments. By breaking down complex algorithms into understandable components (or \"shards\"), we promote transparency and enable users to combine these pieces in creative ways.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install kybershards\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>For full documentation, please visit: API Reference</p>"},{"location":"#license","title":"License","text":"<p>KyberShards is released under the MIT License.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see our contributing guidelines for details on how to get started.</p>"},{"location":"kybershards/documentation/","title":"Documentation","text":"<p>Welcome to the KyberShards API Reference. This section provides detailed documentation for all public modules, classes, and functions in the KyberShards library.</p>"},{"location":"kybershards/documentation/#package-structure","title":"Package Structure","text":"<p>KyberShards is organized into the following sub-packages:</p> <ul> <li>Data Science</li> </ul>"},{"location":"kybershards/dsci/","title":"Data Science","text":"<p>This package includes functionalities for data science and machine learning</p>"},{"location":"kybershards/dsci/typing/","title":"Typing","text":"<p>Type variables.</p>"},{"location":"kybershards/dsci/typing/#kybershards.dsci.typing.LegacySeed","title":"kybershards.dsci.typing.LegacySeed  <code>module-attribute</code>","text":"<pre><code>LegacySeed = int | RandomState | None\n</code></pre>"},{"location":"kybershards/dsci/typing/#kybershards.dsci.typing.Seed","title":"kybershards.dsci.typing.Seed  <code>module-attribute</code>","text":"<pre><code>Seed = (\n    Generator\n    | RandomState\n    | SeedSequence\n    | _ArrayLikeInt_co\n    | None\n)\n</code></pre> <p><code>_ArrayLikeInt_co</code> is any array sequence of <code>int</code> that can be converted to a numpy array. This is defined in the numpy package</p>"},{"location":"kybershards/dsci/utils/","title":"Utilities","text":"<p>Utility functions.</p>"},{"location":"kybershards/dsci/utils/#kybershards.dsci.utils.check_random_state","title":"kybershards.dsci.utils.check_random_state","text":"<pre><code>check_random_state(seed: Seed) -&gt; Generator\n</code></pre> <p>Convert seed into a <code>Generator</code> instance.</p> <p>This function handles different types of random state inputs and standardizes them to a <code>Generator</code> for consistent random number generation.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Seed</code> <p>Source of randomness</p> required <p>Returns:</p> Name Type Description <code>Generator</code> <code>Generator</code> <p>A <code>Generator</code> instance that can be used for random number generation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kybershards.dsci.utils import check_random_state\n&gt;&gt;&gt;\n&gt;&gt;&gt; check_random_state(42)  # Creates Generator with specific seed\n&gt;&gt;&gt; check_random_state(None)  # Creates Generator with random seed\n&gt;&gt;&gt; gen = np.random.default_rng(12345)  # Pass existing Generator\n&gt;&gt;&gt; check_random_state(gen) is gen  # Returns the same object\n&gt;&gt;&gt; rs = np.random.RandomState(12345)  # Convert legacy RandomState\n&gt;&gt;&gt; check_random_state(rs)  # Returns a Generator based on the RandomState\n</code></pre>"},{"location":"kybershards/dsci/datasets/workers_smoking_habits/","title":"Workers Smkoing Habits","text":""},{"location":"kybershards/dsci/datasets/workers_smoking_habits/#kybershards.dsci.datasets.load_workers_smoking_habits","title":"kybershards.dsci.datasets.load_workers_smoking_habits","text":"<pre><code>load_workers_smoking_habits() -&gt; DataFrame\n</code></pre> <p>Load and return the workers smoking habits dataset.</p> <p>This is a classical dataset for correspondence analysis introduced by Greenacre (1984). It contains data on the smoking habits of different employee categories in a company.</p> <p>Dataset Characteristics:</p> Feature Values Employee Categories (rows) Senior-Managers, Junior-Managers, Senior-Employees, Junior-Employees, Secretaries Smoking Habit Levels (columns) None, Light, Medium, Heavy Total Observations 193 employees Data Type Count (frequency) <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame with employee categories as rows and smoking habit levels as columns.</p> <p>The values in the DataFrame represent the frequency counts of employees in each category with each smoking habit level.</p> References <p>Greenacre, M. J. (1984). Theory and Applications of Correspondence Analysis.        London: Academic Press.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = load_workers_smoking_habits()\n&gt;&gt;&gt; print(data)\n                  None  Light  Medium  Heavy\nSenior-Managers      4      2       3      2\nJunior-Managers      4      3       7      4\nSenior-Employees    25     10      12      4\nJunior-Employees    18     24      33     13\nSecretaries         10      6       7      2\n&gt;&gt;&gt; data.sum().sum()  # Total number of employees\n193\n</code></pre>"},{"location":"kybershards/dsci/decomposition/ca/","title":"Correspondence Analysis","text":""},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA","title":"kybershards.dsci.decomposition.CA","text":"<pre><code>CA(\n    n_components: float,\n    *,\n    compute_contributions: bool = False,\n    algorithm: SVDAlgorithm = TRUNCATED,\n    random_state: LegacySeed = None,\n)\n</code></pre> <p>               Bases: <code>ClassNamePrefixFeaturesOutMixin</code>, <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Correspondence Analysis (CA).</p> <p>Correspondence Analysis is a multivariate statistical technique that provides a graphical representation of contingency tables. It finds a low-dimensional representation of the association between rows and columns of the table, similar to how PCA operates but for categorical data.</p> <p>The algorithm decomposes the standardized residuals from independence into principal dimensions that explain the maximum inertia (chi-square distance).</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>float</code> <p>Number of dimensions to keep in the results. When set to a number <code>n</code> between <code>0</code> and <code>1</code>, the <code>n_components</code> is set to the minimum number that explain &gt;= <code>n</code> of inertia.</p> required <code>compute_contributions</code> <code>bool</code> <p>Whether to compute the contributions of rows and columns to the principal dimensions.</p> <code>False</code> <code>algorithm</code> <code>SVDAlgorithm</code> <p>SVD algorithm to use for the decomposition.</p> <code>TRUNCATED</code> <code>random_state</code> <code>LegacySeed</code> <p>Controls the randomness of the SVD solver.</p> <code>None</code> References <p>[1] Benz\u00e9cri, J.-P. (1973). L'Analyse des Donn\u00e9es. Volume II. L'Analyse des        Correspondances. Paris, France: Dunod.</p> <p>[2] Greenacre, M. J. (1984). Theory and Applications of Correspondence Analysis.        London: Academic Press.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kybershards.dsci.datasets import load_workers_smoking_habits\n&gt;&gt;&gt; from kybershards.dsci.decomposition import CA\n&gt;&gt;&gt;\n&gt;&gt;&gt; X = load_workers_smoking_habits()\n&gt;&gt;&gt; ca = CA(n_components=3)\n&gt;&gt;&gt; ca.fit_transform(X)\n    array([[ 0.06576838,  0.193737  ,  0.07098103],\n        [-0.25895842,  0.24330457, -0.03370519],\n        [ 0.38059489,  0.01065991, -0.00515576],\n        [-0.23295191, -0.05774391,  0.00330537],\n        [ 0.20108912, -0.07891123, -0.00808108]])\n</code></pre>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA._n_features_out","title":"_n_features_out  <code>property</code>","text":"<pre><code>_n_features_out: int\n</code></pre> <p>The number of output features returned by the transform method.</p> <p>This property is used by the <code>ClassNamePrefixFeaturesOutMixin</code> to generate appropriate feature names like <code>ca0</code>, <code>ca1</code>, etc. when the transformer is used in a scikit-learn pipeline.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of dimensions in the CA transformed space, which equals the number of components selected during fitting.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.column_components","title":"column_components  <code>property</code>","text":"<pre><code>column_components: NDArray\n</code></pre> <p>Gets the column components (right singular vectors) from the CA decomposition.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>The column components matrix.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.column_contributions","title":"column_contributions  <code>property</code>","text":"<pre><code>column_contributions: NDArray\n</code></pre> <p>Gets the contributions of columns to each principal dimension.</p> <p>The contributions represent how much each column contributes to the definition of each principal dimension. They sum to 1 across all columns for a given dimension.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>Contribution values of columns to dimensions.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.explained_inertia","title":"explained_inertia  <code>property</code>","text":"<pre><code>explained_inertia: NDArray\n</code></pre> <p>Gets the proportion of inertia explained by each principal dimension.</p> <p>Each value represents the proportion of the total inertia (total variance) that is explained by the corresponding principal dimension.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>Proportion of inertia explained by each principal dimension.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.inertia","title":"inertia  <code>property</code>","text":"<pre><code>inertia: NDArray\n</code></pre> <p>Gets the inertia (eigenvalues) of the principal dimensions.</p> <p>The inertia represents the amount of variance explained by each principal dimension, equivalent to the squared singular values.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>Inertia values for each principal dimension.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.row_components","title":"row_components  <code>property</code>","text":"<pre><code>row_components: NDArray\n</code></pre> <p>Gets the row components (left singular vectors) from the CA decomposition.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>The row components matrix.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.row_contributions","title":"row_contributions  <code>property</code>","text":"<pre><code>row_contributions: NDArray\n</code></pre> <p>Gets the contributions of rows to each principal dimension.</p> <p>The contributions represent how much each row contributes to the definition of each principal dimension. They sum to 1 across all rows for a given dimension.</p> <p>Returns:</p> Type Description <code>NDArray</code> <p>Contribution values of rows to dimensions.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.total_inertia","title":"total_inertia  <code>property</code>","text":"<pre><code>total_inertia: float32\n</code></pre> <p>Gets the total inertia of the contingency table.</p> <p>The total inertia is the chi-square statistic of the table divided by the sum of all elements. It represents the total variance in the data that can potentially be explained.</p> <p>Returns:</p> Type Description <code>float32</code> <p>Total inertia of the contingency table.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.column_cosine_similarity","title":"column_cosine_similarity","text":"<pre><code>column_cosine_similarity(\n    X: ArrayLike, G: NDArray\n) -&gt; NDArray\n</code></pre> <p>Compute the cosine similarity between columns in original space and principal dimensions.</p> <p>The cosine similarity represents the quality of representation of the columns in each principal dimension. It measures the proportion of the chi-square distance explained by each dimension.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input contingency table or frequency matrix with non-negative values.</p> required <code>G</code> <code>NDArray</code> <p>Column coordinates in the principal dimensions, which should typically be the output of <code>transform(X, coordinates=Coordinates.COLUMNS)</code>.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Cosine similarity values for each column across all dimensions.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.fit","title":"fit","text":"<pre><code>fit(X: ArrayLike, y: ArrayLike | None = None) -&gt; CA\n</code></pre> <p>Fit the CA model to the data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input contingency table or frequency matrix with non-negative values.</p> required <code>y</code> <code>ArrayLike | None</code> <p>Ignored. Kept for API compatibility with scikit-learn.</p> <code>None</code> <p>Returns:</p> Type Description <code>CA</code> <p>The fitted estimator</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_components is not between 1 and n_features or between 0 and 1.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    X: ArrayLike,\n    y: ArrayLike | None = None,\n    coordinates: Coordinates = ROWS,\n    **fit_params: dict[str, Any],\n) -&gt; NDArray\n</code></pre> <p>Fit the CA model and transform the data in a single step.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input contingency table or frequency matrix with non-negative values.</p> required <code>y</code> <code>ArrayLike | None</code> <p>Ignored. Kept for API compatibility with scikit-learn.</p> <code>None</code> <code>coordinates</code> <code>Coordinates</code> <p>Which coordinates to compute in the princopal dimensions.</p> <p>Note</p> <p>If used as a transformer in a <code>Pipeline</code> with <code>transform_output=\"pandas\"</code>, only <code>ROWS</code> is supported. Transpose your input if you want to project the columns.</p> <code>ROWS</code> <code>fit_params</code> <code>dict[str, Any]</code> <p>Ignored. Kept for API compatibility with scikit-learn.</p> <code>{}</code> <p>Returns:</p> Type Description <code>NDArray</code> <p>Coordinates of rows or columns in the principal dimensions, based on <code>coordinates</code> argument</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_components is not between 1 and n_features or between 0 and 1.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.row_cosine_similarity","title":"row_cosine_similarity","text":"<pre><code>row_cosine_similarity(X: ArrayLike, F: NDArray) -&gt; NDArray\n</code></pre> <p>Compute the cosine similarity between rows in original space and principal dimensions.</p> <p>The cosine similarity represents the quality of representation of the rows in each principal dimension. It measures the proportion of the chi-square distance explained by each dimension.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input contingency table or frequency matrix with non-negative values.</p> required <code>F</code> <code>NDArray</code> <p>Row coordinates in the principal dimensions, which should typically be the output of <code>transform(X, coordinates=Coordinates.ROWS)</code>.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Cosine similarity values for each row across all dimensions.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.CA.transform","title":"transform","text":"<pre><code>transform(\n    X: ArrayLike, coordinates: Coordinates = ROWS\n) -&gt; NDArray\n</code></pre> <p>Transform the data to the principal component space.</p> <p>The transformation projects the input data onto the principal components learned during the fit step.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ArrayLike</code> <p>Input contingency table or frequency matrix with non-negative values.</p> required <code>coordinates</code> <code>Coordinates</code> <p>Which coordinates to compute in the princopal dimensions.</p> <p>Note</p> <p>If used as a transformer in a <code>Pipeline</code> with <code>transform_output=\"pandas\"</code>, only <code>ROWS</code> is supported. Transpose your input if you want to project the columns.</p> <code>ROWS</code> <p>Returns:</p> Type Description <code>NDArray</code> <p>Coordinates of rows or columns in the principal dimensions, based on <code>coordinates</code> argument</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.SVDAlgorithm","title":"kybershards.dsci.decomposition.SVDAlgorithm","text":"<p>               Bases: <code>Enum</code></p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.SVDAlgorithm.FULL","title":"FULL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FULL = 'Full'\n</code></pre>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.SVDAlgorithm.TRUNCATED","title":"TRUNCATED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRUNCATED = 'Truncated'\n</code></pre>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.Coordinates","title":"kybershards.dsci.decomposition.Coordinates","text":"<p>               Bases: <code>Enum</code></p> <p>Type of coordinates to compute.</p>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.Coordinates.COLUMNS","title":"COLUMNS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COLUMNS = 'Columns'\n</code></pre>"},{"location":"kybershards/dsci/decomposition/ca/#kybershards.dsci.decomposition.Coordinates.ROWS","title":"ROWS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ROWS = 'Rows'\n</code></pre>"}]}